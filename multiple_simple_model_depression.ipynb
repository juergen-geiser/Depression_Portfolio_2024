{"cells":[{"cell_type":"markdown","metadata":{},"source":["Multiple simple model based on the depression-data-set:\n","\n","Idea: We have a basic dataset, which is given in: https://www.kaggle.com/datasets/shahzadahmad0402/depression-and-anxiety-data\n","\n","\n","We deal with 4 different target-columns, which are related to different feature_columns, e.g., detected wth Power BI or with ML (feature importance):\n","\n","1.) Prediction of `anxiousness` (Target variable: 0 (False) / 1 (True))\n","\n","    good feature variables:\n","\n","    - phq_score: it is a measure of depression, higher values ​​deal with more general psychological distress.\n","\n","    - gender: Gender-specific differences in susceptibility to anxiety disorders (often females are more anxious).\n","\n","    - age: Age groups can react differently to fear.\n","\n","\n","2.) Prediction of `depressiveness` (Target variable: 0 (False) / 1 (True))\n","\n","    good feature variables:\n","\n","    - phq_score: A direct indicator of depression.\n","\n","    - gender: Gender-specific differences in susceptibility to depression.\n","\n","    - age: Age groups can react differently to depression.\n","\n","    - sleepiness: Sleep disorders can be an indication of depressive symptoms.\n","\n","\n","3.) Prediction of `will_get_treatment (Target variable: 0 (False) / 1 (True))\n","\n","    good feature variables:\n","\n","    - phq_score: More severe depression may be more likely to require treatment.\n","\n","    - depression_severity: Higher levels of depression severity increase the likelihood of treatment.\n","\n","    - age: Age groups have different access to treatment.\n","\n","    - depression_diagnosis: A formal diagnosis can increase the likelihood of treatment.\n","\n","    - sleepiness: Sleep disorders can increase the need for treatment.\n","\n","\n","4.) Prediction of `suicidality` (Target variable: False (no suicidality) / 1: True (suicidality))\n","\n","    possible feature variables:\n","\n","    - phq_score: A higher value can correlate with suicidality.\n","\n","    - depression_severity: Higher levels of depression increase the risk of suicide.\n","\n","    - depressiveness: Direct indicator of depressive symptoms.\n","\n","    - age: Age groups have different suicide rates.\n","\n","    - gender: Gender-specific differences in susceptibility to suicide.\n","    \n","    - Sleepiness: Sleep disorders often correlate with suicide risk.\n"]},{"cell_type":"markdown","metadata":{},"source":["We apply a multiple depression model, which is done in the kaggle-work: https://www.kaggle.com/code/geovaniwoll/machine-learningproject \n","We classify the target depressiveness, with the three columns (features): gender, phq_score, gad_score,\n","see also the given description of the dataset, above and given in the Kaggle_work: https://www.kaggle.com/datasets/shahzadahmad0402/depression-and-anxiety-data"]},{"cell_type":"markdown","metadata":{},"source":["| **Column** | **Description** |\n","| ------------ | :-----------------: |\n","| id | each number is a participant in the experiment |\n","| school_year | years in school |\n","| age | |\n","| gender | |\n","| bmi | body mass index |\n","| who_bmi | bmi category |\n","| phq_score | measure the severity of symptoms related to depression, anxiety, and other related disorders in patients |\n","| depression_severity | degree or intensity of symptoms experienced by an individual with depression |\n","| depressiveness | |\n","| suicidal | the candidate have suicide thought |\n","| depression_diagnosis | the candidate already have depression diagnosis |\n","| depression_treatment | the candidate already have depression treatment |\n","| gad_score | measure that assesses the severity of Generalized Anxiety Disorder |\n","| anxiety_severity |  intensity of symptoms experienced by an individual with anxiety |\n","| anxiousness | |\n","| anxiety_diagnosis | the candidate already have anxiety diagnosis |\n","| anxiety_treatment | the candidate already have anxiety treatment |\n","| epworth_score |  score to assess daytime sleepiness ytime sleepiness |\n","| sleepiness | |"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.utils import resample"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read the csv-data\n","df = pd.read_csv('data/depression_anxiety_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# see the data\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nData-Types of the columns:\")\n","display(df.dtypes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#check NaNs and duplicates\n","print('Index')\n","print('index_size', df.index.size)\n","print('Columns with NaN')\n","print('is NaN', df.isna().sum())\n","print('Duplicates in Columns')\n","print('duplicated', df.duplicated().sum())\n","#note: no NaNs, no duplicates, no cleaning required"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Modells with targets and features\n","\n","# Target columns (later we put 'depression_treatment', 'anxiety_treatment' together to 'treatment_status')\n","\n","target_cols =['anxiousness', 'depressiveness', 'depression_treatment', 'anxiety_treatment', 'suicidal']\n","\n","# first all numerical columns\n","\n","num_cols =  ['school_year', 'age', 'bmi', 'phq_score', 'gad_score', 'epworth_score' ]\n","\n","\n","# categorical columns, which can be transformed simple to numerical columns (only true/false entires)\n","\n","cat_cols_trans = ['gender', 'depression_diagnosis', 'depression_treatment',  'anxiety_diagnosis', 'sleepiness']\n","\n","\n","# We have 3 catergoical columns with more that 2 entries:\n","\n","cat_cols = ['who_bmi', 'anxiety_severity', 'depressiv_severity']\n","\n","\n","# We could clean"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data-cleaning\n","\n","# Drop all NaNs (we have ony a few NaNs in the columns): \n","df = df.dropna()\n","\n","\n","# Correct Datatypes of the target:\n","# and the feature gender (both int)\n","\n","df.gender = df.gender.map({'male':1, 'female':0})\n","\n","\n","# Define the targets:\n","#1.) anxiousness:  Prediction:  0: False (no anxious) / 1: True (anxious)\n","#2.) depressiveness: Prediction: 0: False (no depression) / 1: True (depression)\n","#3.) will_get_treatment: Prediction: 0: False (no get-treatement) / 1: True (get-treatment)\n","#4.) suicidality: Prediction: 0: False (no suicidality) / 1: True (suicidality)\n","\n","df['anxiousness'] = df['anxiousness'].astype(int)\n","df['depressiveness'] = df['depressiveness'].astype(int)\n","\n","df['treatment_status'] = df['depression_treatment'] | df['anxiety_treatment']\n","df['treatment_status'] = df['treatment_status'].astype(int)\n","\n","\n","df['suicidal'] = df['suicidal'].astype(int)\n","\n","# Change the binary categorial feature variables into numerical \n","\n","# Convert binary categorical features to integer\n","df[cat_cols_trans] = df[cat_cols_trans].astype(int)\n","\n","\n","\n","\n","# Describe the dates\n","display(df.describe())\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","metadata":{},"source":["**Most important features, given by the clinical test:**\n","- gender\n","- phd_score\n","- gad_score"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# correlation of the three important features:  gender, gad_score, phq_score \n","\n","correlation_matrix = df[['gender', 'phq_score', 'gad_score']].corr()\n","print(correlation_matrix)\n","\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Set the size of the plot\n","plt.figure(figsize=(8, 6))\n","\n","# Create the heatmap\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n","\n","# Set the title\n","plt.title('Correlation Heatmap')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["**Exploration of the dataset with the important features**\n","\n","We apply sns-plots"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# Define your target and numerical columns\n","target_cols = ['anxiousness', 'depressiveness', 'treatment_status', 'suicidal']\n","num_cols = ['gender', 'phq_score', 'gad_score']\n","\n","# Iterate over each numerical column\n","for num_col in num_cols:\n","    # Iterate over each target column\n","    for target_col in target_cols:\n","        # Create the figure and axes for the plots\n","        fig, axes = plt.subplots(2, 1, figsize=(20, 6), sharex=True, gridspec_kw={'height_ratios': [5, 1]})\n","        \n","        # Histogram\n","        sns.histplot(data=df, x=num_col, hue=target_col, kde=True, multiple=\"stack\", ax=axes[0])\n","        axes[0].set_title(f'Histogram of {num_col} by {target_col}')\n","        \n","        # Boxplot\n","        sns.boxplot(data=df, x=num_col, hue=target_col, ax=axes[1])\n","        axes[1].set_title(f'Boxplot of {num_col} by {target_col}')\n","        \n","        # Titles of the axes and display the plot\n","        axes[1].set_xlabel(num_col)\n","        axes[1].set_ylabel('')\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["* Base model with the training and test datasets of all the 4 different targets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Define your target columns\n","target_cols = ['anxiousness', 'depressiveness', 'treatment_status', 'suicidal']\n","\n","# Define the feature columns for each model\n","feature_sets = {\n","    'anxiousness': ['phq_score', 'gender', 'age'],\n","    'depressiveness': ['phq_score', 'gender', 'age', 'sleepiness'],\n","#    'treatment_status': ['phq_score', 'depression_severity', 'age', 'depression_diagnosis', 'sleepiness'],  # here, we have one categorical column: depression_severity\n","    'treatment_status': ['phq_score', 'age', 'depression_diagnosis', 'sleepiness'],\n","    'suicidal': ['phq_score', 'depressiveness', 'age', 'gender', 'sleepiness']\n","}\n","\n","# Initialize an empty list to store the models\n","models = []\n","\n","# Iterate over each target column\n","for target in target_cols:\n","    # Select the corresponding features for the current target\n","    X = df[feature_sets[target]]\n","    y = df[target]\n","    \n","    # Split the train and test dataset\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    \n","    # Apply a simple logistic regression model\n","    model = LogisticRegression()\n","    \n","    # Fit the model\n","    model.fit(X_train, y_train)\n","    \n","    # Append the fitted model to the list\n","    models.append(model)\n","    \n","    # Predict the model\n","    y_pred = model.predict(X_test)\n","    \n","    # Calculate the accuracy\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy for {target}: {accuracy}\")\n","    \n","    # Apply a first prediction\n","    print(f\"Classification report for {target}:\\n{classification_report(y_test, y_pred)}\")\n","\n","# The models list now contains the fitted models for each target\n","# models[0] -> model for 'anxiousness'\n","# models[1] -> model for 'depressiveness'\n","# models[2] -> model for 'treatment_status'\n","# models[3] -> model for 'suicidal'\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data-cleaing of the aim-data set:\n","\n","# This is the connection to the ML part, we need also the function: clean_data, feature_engineering etc. what we did with the dates in the ML part\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Define your target columns\n","target_cols = ['anxiousness', 'depressiveness', 'treatment_status', 'suicidal']\n","\n","# Define the feature columns for each model\n","feature_sets = {\n","    'anxiousness': ['phq_score', 'gender', 'age'],\n","    'depressiveness': ['phq_score', 'gender', 'age', 'sleepiness'],\n","    'treatment_status': ['phq_score', 'age', 'depression_diagnosis', 'sleepiness'],\n","    'suicidal': ['phq_score', 'depressiveness', 'age', 'gender', 'sleepiness']\n","}\n","\n","# Initialize an empty list to store the models\n","models = []\n","\n","# Iterate over each target column\n","for target in target_cols:\n","    # Select the corresponding features for the current target\n","    X = df[feature_sets[target]]\n","    y = df[target]\n","    \n","    # Split the train and test dataset\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    \n","    # Apply a simple logistic regression model\n","    model = LogisticRegression()\n","    \n","    # Fit the model\n","    model.fit(X_train, y_train)\n","    \n","    # Append the fitted model to the list\n","    models.append(model)\n","    \n","    # Predict the model\n","    y_pred = model.predict(X_test)\n","    \n","    # Calculate the accuracy\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy for {target}: {accuracy}\")\n","    \n","    # Print classification report\n","    print(f\"Classification report for {target}:\\n{classification_report(y_test, y_pred)}\")\n","\n","# The models list now contains the fitted models for each target\n","# models[0] -> model for 'anxiousness'\n","# models[1] -> model for 'depressiveness'\n","# models[2] -> model for 'treatment_status'\n","# models[3] -> model for 'suicidal'\n","\n","\n","# Define the status names for each model\n","status_names = {\n","    'anxiousness': ['non-anxious', 'anxious'],\n","    'depressiveness': ['non-depressive', 'depressive'],\n","    'treatment_status': ['not in treatment', 'in treatment'],\n","    'suicidal': ['non-suicidal', 'suicidal']\n","}\n","\n","# Reading the cleaned CSV file into a DataFrame\n","X_aim = pd.read_csv('aim_test_cleaned.csv')  # Ensure this file is cleaned similarly to the training data\n","\n","# Ensure X_aim has the same features as used for training\n","for i, target in enumerate(target_cols):\n","    # Select the corresponding features for the current target in the aim dataset\n","    X_aim_target = X_aim[feature_sets[target]]\n","    \n","    # Predict using the corresponding model\n","    y_pred_aim = models[i].predict(X_aim_target)\n","    print(f\"Predictions for {target}:\")\n","    \n","    # Format the predictions for better readability\n","    for j, prediction in enumerate(y_pred_aim, start=1):\n","        status = status_names[target][prediction]\n","        print(f'person{j} is {status}')\n"]},{"cell_type":"markdown","metadata":{},"source":["**Improvement of the model, via oversampling to balance the target (we apply it for all the targets)**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.utils import resample\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Define your target columns\n","target_cols = ['anxiousness', 'depressiveness', 'treatment_status', 'suicidal']\n","\n","# Define the feature columns for each model\n","feature_sets = {\n","    'anxiousness': ['phq_score', 'gender', 'age'],\n","    'depressiveness': ['phq_score', 'gender', 'age', 'sleepiness'],\n","    'treatment_status': ['phq_score', 'age', 'depression_diagnosis', 'sleepiness'],\n","    'suicidal': ['phq_score', 'depressiveness', 'age', 'gender', 'sleepiness']\n","}\n","\n","# Initialize an empty list to store the models\n","models = []\n","\n","# Iterate over each target column\n","for target in target_cols:\n","    # Select the corresponding features and target for the current model\n","    X = df[feature_sets[target]]\n","    y = df[target]\n","    \n","    # Separate the majority and minority classes\n","    data_majority = df[df[target] == 0]\n","    data_minority = df[df[target] == 1]\n","    \n","    # Oversample the minority class\n","    data_minority_oversampled = resample(data_minority, \n","                                         replace=True, \n","                                         n_samples=len(data_majority), \n","                                         random_state=42)\n","    \n","    # Combine the majority class with the oversampled minority class\n","    df_oversampled = pd.concat([data_majority, data_minority_oversampled])\n","    \n","    # Update X and y with the oversampled data\n","    X = df_oversampled[feature_sets[target]]\n","    y = df_oversampled[target]\n","    \n","    # Split the train and test dataset\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    \n","    # Apply a simple logistic regression model\n","    model = LogisticRegression()\n","    \n","    # Fit the model\n","    model.fit(X_train, y_train)\n","    \n","    # Append the fitted model to the list\n","    models.append(model)\n","    \n","    # Predict the model\n","    y_pred = model.predict(X_test)\n","    \n","    # Calculate the accuracy\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(f\"Accuracy for {target}: {accuracy}\")\n","    \n","    # Print the classification report\n","    print(f\"Classification report for {target}:\\n{classification_report(y_test, y_pred)}\")\n","\n","# The models list now contains the fitted models for each target\n","# models[0] -> model for 'anxiousness'\n","# models[1] -> model for 'depressiveness'\n","# models[2] -> model for 'treatment_status'\n","# models[3] -> model for 'suicidal'\n"]},{"cell_type":"markdown","metadata":{},"source":["**Final predictions with an own or given dataset: aim_test.csv**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Reading the cleaned CSV file into a DataFrame\n","X_aim = pd.read_csv('aim_test_cleaned.csv')  # Ensure this file is cleaned similarly to the training data\n","\n","# Ensure X_aim has the same features as used for training\n","for i, target in enumerate(target_cols):\n","    # Select the corresponding features for the current target in the aim dataset\n","    X_aim_target = X_aim[feature_sets[target]]\n","    \n","    # Predict using the corresponding model\n","    y_pred_aim = models[i].predict(X_aim_target)\n","    print(f\"Predictions for {target}:\")\n","    \n","    # Format the predictions for better readability\n","    for j, prediction in enumerate(y_pred_aim, start=1):\n","        status = status_names[target][prediction]\n","        print(f'person{j} is {status}')\n"]},{"cell_type":"markdown","metadata":{},"source":["* We apply a simplified depression model, which are based on the three important feature: gander, phq_score and gad_score.\n","We could apply a logistic regression model for the classification and obtain good clasifiactions.\n","Based on the fitted model we apply the predictio to an own data set.\n","Such a simple model culd be used as a first classification of depressiveness.*\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","import pandas as pd\n","\n","# Angenommen, 'models' ist dein trainiertes Modell mit den Einträgen models[0], models[1], ..., models[3]\n","# Speichere das Modell in einer Datei\n","#with open('model.pkl', 'wb') as file:\n","#    pickle.dump(model, file)\n","\n","\n","with open('models.pkl', 'wb') as file:\n","    pickle.dump(models, file)\n","    pickle.dump(status_names, file)\n","    pickle.dump(target_cols, file)\n","    pickle.dump(feature_sets, file)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2374095,"sourceId":4002279,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
